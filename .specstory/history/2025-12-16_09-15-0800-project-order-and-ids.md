<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session fa829d6f-5847-4a51-b0fc-b3537810629e (2025-12-16 09:15-0800) -->

# Project order and IDs (2025-12-16 09:15-0800)

_**User**_

@src/components/ProjectsSection.tsx:18-210 Your goal is to move the projects around and change their ids. So I want:
Tactico AI - 1
Vocal AI - 2
iQore - 3
MyBuddy - 4
WonderKid - 5
EchoLens - 6
Traveler AI - 7

---

_**Agent (model default, mode Agent)**_



---


Reordering the projects array and updating IDs. Reading the full file to understand the structure.


---

<tool-use data-tool-type="read" data-tool-name="read_file_v2">
<details><summary>Tool use: **read_file_v2** • Read file: c:\Users\ramis\OneDrive\Desktop\Programming\my-website\my-website\src\components\ProjectsSection.tsx</summary>

</details>
</tool-use>

---



---


Reordering the projects array and updating IDs to match the requested order.


---

<tool-use data-tool-type="write" data-tool-name="edit_file_v2">

<details><summary>Tool use: **edit_file_v2**</summary>

```typescriptreact
  const projects = [
    {
      id: 1,
      title: "TacticoAI",
      description: "AI tactical analysis for college sports—upload match footage and get player tracking, possession, and team insights.",
      fullDescription: "TacticoAI is an AI-powered tactical analysis platform for college sports teams that turns raw match footage into actionable performance insights. Built with a React + TypeScript frontend and a FastAPI backend, it supports chunked video uploads, background job processing, and persistent storage via Supabase (PostgreSQL + Storage). The core ML pipeline uses YOLO-based detection with ByteTrack multi-object tracking to identify players and the ball, automatically assigns teams via jersey color clustering (K-means), tracks ball possession, and estimates real-world speed and distance using camera movement compensation and perspective transformation from pixel space to field coordinates. Results are delivered as annotated output video overlays plus per-frame tracking data and summary statistics for tactical review and export.",
      logo: "/images/logo-tactico-ai.jpg",
      image: "/images/tactico-ai-1.jpg",
      images: [
        "/images/tactico-ai-1.jpg",
        "/images/tactico-ai-2.jpg",
        "/images/tactico-ai-3.jpg",
        "/images/tactico-ai-4.jpg",
        "/images/tactico-ai-5.jpg"
      ],
      categories: ["Hackathon", "ML"],
      demoUrl: "https://www.youtube.com/watch?v=RSF-UM9DC4A",
      devpostUrl: "https://devpost.com/software/tactico-ai",
      githubUrl: "https://github.com/ramizik/tactico-ai",
      keyFeatures: [
        "Chunked upload for large match videos",
        "YOLO + ByteTrack player/ball detection and tracking",
        "Automatic team assignment via jersey color clustering (K-means)",
        "Ball possession tracking and team control metrics",
        "Real-world speed and distance estimation with camera compensation",
        "Perspective transform from pixels to field coordinates with data export"
      ]
    },
    {
      id: 2,
      title: "Vocal AI",
      description: "Vocal coaching platform with real-time analysis and conversational agents—Hackathon winner.",
      fullDescription: "VocalAI is an AI-powered vocal coaching platform that won Most Ambitious Vapi Project at UC Berkeley's AI Hackathon 2025. Built with React/TypeScript and FastAPI, it integrates multiple AI services including Letta for stateful conversational coaching, Fetch.ai for autonomous progress analysis, and VAPI for real-time voice conversations. The platform performs comprehensive vocal analysis using Web Audio API to extract metrics like pitch, jitter, shimmer, and vibrato rate, then generates personalized exercises and feedback through AI agents with long-term memory. Data is managed through Supabase PostgreSQL with the system providing both reactive chat-based coaching and proactive daily reports to track vocal development over time.",
      logo: "/images/logo-vocal-ai.png",
      image: "/images/vocal-ai-1.jpg",
      images: [
        "/images/vocal-ai-0.jpg",
        "/images/vocal-ai-1.jpg",
        "/images/vocal-ai-2.jpg",
        "/images/vocal-ai-3.jpg",
        "/images/vocal-ai-4.jpg",
        "/images/vocal-ai-5.jpg",
        "/images/vocal-ai-6.jpg",
        "/images/vocal-ai-7.JPEG",
        "/images/vocal-ai-8.JPEG"
      ],
      categories: ["Hackathon", "API"],
      demoUrl: "https://www.youtube.com/watch?v=4XWiMuE9wwM&t=119s",
      devpostUrl: "https://devpost.com/software/vocai-ai-coach",
      githubUrl: "https://github.com/ramizik/vocal-ai",
      keyFeatures: [
        "Real-time vocal analysis",
        "AI-powered feedback system",
        "Pitch detection and correction",
        "Progress tracking dashboard",
        "Custom training exercises",
        "Performance analytics"
      ]
    },
    {
      id: 3,
      title: "Business Chatbot for iQore",
      description: "Multi-agent convention chatbot—20% more client interactions at IEEE Quantum event.",
      fullDescription: "iQore Multi-Agent Event Chatbot is an enterprise AI system built for iQore's IEEE Quantum Convention featuring four specialized agents powered by LangGraph, LangChain, and OpenAI GPT-3.5-turbo with RAG knowledge retrieval. Built with FastAPI and MongoDB Atlas, the system engaged clients directly while supporting human representatives with instant company information access. This hybrid approach enabled iQore to process 20% more interactions than previous conventions by autonomously handling qualification, technical Q&A, and demo scheduling. Deployed on Google Cloud Run with real-time queue management, demonstrating effective AI-human collaboration in high-traffic convention environments.",
      logo: "/images/logo-iqore.png",
      image: "/images/iqore-1.jpg",
      images: [
        "/images/iqore-1.jpg",
        "/images/iqore-2.jpg",
        "/images/iqore-3.jpg"
      ],
      categories: ["RAG", "Multi-Agent"],
      demoUrl: "",
      devpostUrl: "",
      githubUrl: "https://github.com/ramizik/iqore",
      keyFeatures: [
        "RAG-powered knowledge retrieval",
        "Multi-agent coordination system",
        "Context-aware conversations",
        "Document processing pipeline",
        "Intent classification",
        "Automated escalation system"
      ]
    },
    {
      id: 4,
      title: "My Buddy",
      description: "Cloud AI assistant managing calendar, tasks, budget & habits via Telegram with proactive reminders",
      fullDescription: "My Buddy is a cloud-native personal assistant built with AWS serverless architecture, currently in development as my vision of a proactive AI companion. The system integrates Google Calendar API, Telegram Bot API, and AWS services (Lambda, DynamoDB, EventBridge) to track calendar events, tasks, budget, streaks, goals, and projects through conversational commands. EventBridge orchestrates hourly reminders and morning/evening summaries with visual task prioritization. With Phase 2 operational, Phase 3 targets LangChain integration for intelligent analysis and memory—transforming it from reactive to proactive, anticipating needs and providing contextual insights to achieve an always-available intelligent companion working silently in the cloud.",
      logo: "/images/logo-my-buddy.png",
      image: "/images/my-buddy-1.jpg",
      images: [
        "/images/my-buddy-1.jpg",
        "/images/my-buddy-2.jpg",
        "/images/my-buddy-3.jpg",
        "/images/my-buddy-4.jpg",
        "/images/my-buddy-5.jpg",
        "/images/my-buddy-6.jpg",
        "/images/my-buddy-7.jpg",
        "/images/my-buddy-8.jpg"
      ],
      categories: ["Mobile App", "API"],
      demoUrl: "",
      devpostUrl: "",
      githubUrl: "https://github.com/ramizik/ai-helper/tree/main",
      keyFeatures: [
        "AI-powered task management",
        "Smart calendar integration",
        "Personalized recommendations",
        "Voice command support",
        "Cross-platform synchronization",
        "Privacy-focused design"
      ]
    },
    {
      id: 5,
      title: "WonderKid",
      description: "AI-powered interactive storytelling app for kids with dynamic stories, illustrations & videos",
      fullDescription: "WonderKid is an AI-powered interactive reading game for children aged 5-8, built at Big Red Hacks 2025. It combines Google's Gemini for dynamic story generation, Imagen for custom illustrations, and Veo 2.0 for video compilation. Kids input story themes and make choices that shape personalized narratives across 6 scenes, each with unique AI-generated artwork. After completion, the entire adventure compiles into a shareable video. The React Native mobile app features gradient-rich UI and progress tracking, while the FastAPI backend orchestrates AI integrations with MongoDB and Google Cloud Storage. This project demonstrates full-stack development, real-time AI orchestration, and child-focused UX design.",
      logo: "/images/logo-wonder-kid.png",
      image: "/images/wonder-kid-1.jpg",
      images: [
        "/images/wonder-kid-1.jpg",
        "/images/wonder-kid-2.jpg",
        "/images/wonder-kid-3.jpg",
        "/images/wonder-kid-4.jpg",
        "/images/wonder-kid-5.jpg",
        "/images/wonder-kid-6.jpg",
        "/images/wonder-kid-7.jpg"
      ],
      categories: ["Hackathon", "Mobile App", "Multi-Modal"],
      demoUrl: "",
      devpostUrl: "https://devpost.com/software/wonderkid",
      githubUrl: "https://github.com/ramizik/bigredhacks25",
      keyFeatures: [
        "AI story generation",
        "Dynamic illustrations with Imagen",
        "Interactive story choices",
        "Video compilation with Veo 2.0",
        "Progress tracking",
        "Age-appropriate content"
      ]
    },
    {
      id: 6,
      title: "EchoLens",
      description: "AI accessibility tool translating audio environments into visual info for deaf users.",
      fullDescription: "EchoLens is an AI-powered accessibility tool that translates audio environments into visual information for deaf and hard-of-hearing users. Built with React and Flask, it uses Google's Gemini AI and TensorFlow's YAMNet to provide real-time speech transcription, emotion detection, and spatial sound classification. The system identifies environmental sounds (doorbells, alarms, vehicles) and determines their direction through stereo audio processing. Features include an interactive 360° sound map, emotion-aware AI assistant, and customizable visualizations—demonstrating practical integration of speech recognition, audio event detection, and multimodal AI to enhance situational awareness and safety.",
      logo: "/images/logo-echolens.png",
      image: "/images/echo-lens-1.png",
      images: [
        "/images/echo-lens-1.png",
        "/images/echo-lens-2.png",
        "/images/echo-lens-3.png",
        "/images/echo-lens-4.png",
        "/images/echo-lens-4.JPEG"
      ],
      categories: ["Multi-Modal", "Hackathon"],
      demoUrl: "https://www.youtube.com/watch?v=HJFwOpEGalA",
      devpostUrl: "https://devpost.com/software/echolens-oujfr0",
      githubUrl: "https://github.com/ramizik/echolens.ai",
      keyFeatures: [
        "Real-time audio transcription",
        "Environmental sound detection",
        "Visual audio feedback",
        "Multi-modal interface",
        "Customizable audio profiles",
        "Accessibility-focused design"
      ]
    },
    {
      id: 7,
      title: "Traveler AI",
      description: "AI travel planner with multimodal chat, itinerary generation & real-time data integration",
      fullDescription: "Traveler AI is a multimodal conversational travel planner built during Google's 5-day Gen AI Intensive Course. Powered by Gemini 2.0 Flash and 1.5 Pro Vision, it combines intelligent itinerary building with real-time data from OpenWeather and Ticketmaster APIs. The assistant understands natural language and tourist photos, offering personalized suggestions through RAG-powered cultural tips (ChromaDB + embeddings), OCR translation, landmark descriptions, and YouTube video summarization. It features an LLM-based self-evaluation system that scores each itinerary on weather suitability, personalization, and authenticity. Users can export plans as Markdown or PDF, take interactive travel quizzes, and maintain session memory of preferences and destinations—all through a Python CLI chatbot experience in Kaggle Notebooks.",
      logo: "/images/logo-travel-ai.png",
      image: "/images/profile.jpg",
      images: [],
      categories: ["Multi-Agent", "Multi-Modal", "RAG", "Hackathon"],
      demoUrl: "https://www.youtube.com/watch?v=c_hut9NcQwY",
      devpostUrl: "https://devpost.com/software/travel-ai-agent",
      githubUrl: "https://github.com/ramizik/travelai-gemini-agent",
      keyFeatures: [
        "Multi-modal destination analysis",
        "RAG-powered recommendations",
        "Personalized itinerary generation",
        "Real-time travel information",
        "Budget optimization",
        "Interactive map integration"
      ]
    }
  ];
```

</details>

</tool-use>

---



---


Reordered the projects array and updated IDs:

- TacticoAI — id: 1 (moved from position 7)
- Vocal AI — id: 2 (moved from position 1)
- iQore — id: 3 (moved from position 2)
- My Buddy — id: 4 (moved from position 3)
- WonderKid — id: 5 (moved from position 4)
- EchoLens — id: 6 (unchanged)
- Traveler AI — id: 7 (moved from position 5)

Checking for linting errors:


---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** • Read lints for 1 file</summary>
      
Lint paths:

- `src/components/ProjectsSection.tsx`

Lint results

Lint errors for `src/components/ProjectsSection.tsx`


| Message | Range | Severity |
|-------|-------|----------|
| Property 'children' is missing in type '\{ isOpen: boolean; onClose: () => void; \}' but required in type 'SimpleModalProps'. | 463:8-463:19 | DIAGNOSTIC_SEVERITY_ERROR |
| Type '\{ key: number; variant: string; className: string; \}' is not assignable to type 'BadgeProps'.<br/>  Property 'key' does not exist on type 'BadgeProps'. | 471:26-471:29 | DIAGNOSTIC_SEVERITY_ERROR |


</details>
</tool-use>

---



---


Reordering complete. The lint errors are pre-existing and unrelated to the reordering.

**Summary:**
- Reordered the projects array to the requested order
- Updated all project IDs (1-7) to match the new positions
- All project data (descriptions, images, links, etc.) preserved

The projects now display in this order:
1. TacticoAI
2. Vocal AI
3. iQore
4. My Buddy
5. WonderKid
6. EchoLens
7. Traveler AI

Should I fix the pre-existing TypeScript lint errors in this file?

---

_**User**_

@src/components/TimelineSection.tsx:135-137 We don't want to be repetetive about description of a project like we have in project section. Adjust, make it more compact here in TimelLine

---

_**Agent (model default, mode Agent)**_



---

Reviewing TimelineSection.tsx to make the description more compact and less repetitive.


---

<tool-use data-tool-type="read" data-tool-name="read_file_v2">
<details><summary>Tool use: **read_file_v2** • Read file: c:\Users\ramis\OneDrive\Desktop\Programming\my-website\my-website\src\components\TimelineSection.tsx</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file_v2">
<details><summary>Tool use: **read_file_v2** • Read file: c:\Users\ramis\OneDrive\Desktop\Programming\my-website\my-website\src\components\ProjectsSection.tsx</summary>

</details>
</tool-use>

---



---

Making the Tactico AI description in TimelineSection more compact and consistent with the other timeline entries.


---

<tool-use data-tool-type="write" data-tool-name="edit_file_v2">

<details><summary>Tool use: **edit_file_v2**</summary>

```typescriptreact
      description: "AI tactical analysis platform for college sports teams that turns match footage into actionable insights. Uses YOLO + ByteTrack for player/ball tracking, automatic team assignment, and real-world metrics estimation.",
```

</details>

</tool-use>

---



---

Made the Tactico AI description more compact. It now matches the style of other timeline entries and avoids repeating details already in the achievements list.

**What changed:**
- Reduced the description from a long paragraph to a concise 2-sentence summary
- Focused on the core value proposition (tactical analysis for sports teams)
- Highlighted key technical features (YOLO + ByteTrack, team assignment, metrics) without excessive detail
- Technical details remain in the achievements list for those who want more information

The description is now consistent with other timeline entries like EchoLens, Traveler AI, and Vocal AI.

---

_**User**_

@src/components/TrackerPage.tsx:11-40 add a new event here with id 1, call it "LA Hackathon" and put date of 2026-01-24

---

